{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne_bids import (BIDSPath, read_raw_bids, find_matching_paths)\n",
    "import xarray as xr\n",
    "# from ptsa.data.timeseries import TimeSeries\n",
    "import os\n",
    "# import cmldask.CMLDask as da\n",
    "# import cmlreaders as cml\n",
    "import pickle\n",
    "\n",
    "def mne_to_ptsa(ep):\n",
    "    '''Create an PTSA TimeSeries (essentially xarray) version of MNE epoch data'''\n",
    "    assert ep.metadata is not None, \"Please define mne.Epoch.metadata\"\n",
    "    x = TimeSeries(ep.get_data(copy=True), dims=('event','channel','time'),\n",
    "                   coords={'event':pd.MultiIndex.from_frame(ep.metadata),\n",
    "                           'channel':ep.info['ch_names'],\n",
    "                           'time':ep.times,\n",
    "                           'samplerate':ep.info['sfreq']})\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'LTP453'\n",
    "settings_path = \"settings/phase1_settings.pkl\"\n",
    "settings = pickle.load(open(settings_path, 'rb'))\n",
    "# data = cml.get_data_index(kind = 'ltp')\n",
    "# data = data[(data['experiment']==settings['experiment'])&(data['subject']==subject)].sort_values('session').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rel_start': 300,\n",
       " 'rel_stop': 1300,\n",
       " 'buffer_time': 500,\n",
       " 'freqs': array([  6.        ,   9.75368156,  15.85571732,  25.77526961,\n",
       "         41.90062864,  68.11423148, 110.72742057, 180.        ]),\n",
       " 'width': 5,\n",
       " 'experiment': 'NiclsCourierReadOnly',\n",
       " 'clean': 0,\n",
       " 'save': 1,\n",
       " 'reference': 'average'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('settings/phase2_settings_early_prestimulus.pkl', 'wb') as f:\n",
    "    pickle.dump(settings.__dict__, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_root = \"/data8/NICLS_BIDS\"\n",
    "bids_path = BIDSPath(subject=subject, root=bids_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 120 events and 4097 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104457/3607145207.py:12: RuntimeWarning: The unit for channel(s) EXG5, EXG6, EXG7, EXG8 has changed from V to NA.\n",
      "  raw = read_raw_bids(bids_path, extra_params={\"infer_types\":True}, verbose=False)\n",
      "/tmp/ipykernel_104457/3607145207.py:12: RuntimeWarning: The unit for channel(s) Status has changed from NA to V.\n",
      "  raw = read_raw_bids(bids_path, extra_params={\"infer_types\":True}, verbose=False)\n",
      "/tmp/ipykernel_104457/3607145207.py:12: RuntimeWarning: There are channels without locations (n/a) that are not marked as bad: ['EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', 'EXG8', 'Status']\n",
      "  raw = read_raw_bids(bids_path, extra_params={\"infer_types\":True}, verbose=False)\n",
      "/tmp/ipykernel_104457/3607145207.py:12: RuntimeWarning: Not setting positions of 9 eog/misc/stim channels found in montage:\n",
      "['EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', 'EXG8', 'Status']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = read_raw_bids(bids_path, extra_params={\"infer_types\":True}, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 15 columns\n"
     ]
    }
   ],
   "source": [
    "bids_paths = find_matching_paths(\n",
    "    bids_root, \n",
    "    subjects=subject, \n",
    "    tasks=\"NiclsCourierReadOnly\",\n",
    "    datatypes=\"eeg\",\n",
    "    extensions=\".bdf\"\n",
    "    )\n",
    "all_sessions = []\n",
    "for bids_path in bids_paths[0:1]:\n",
    "    events_path = bids_path.copy().update(suffix=\"events\", extension=\".tsv\")\n",
    "    event_df = pd.read_csv(events_path, sep=\"\\t\")\n",
    "    raw = read_raw_bids(bids_path, extra_params={\"infer_types\":True}, verbose=False)\n",
    "    mne_events, mne_event_id = mne.events_from_annotations(raw, verbose=False)\n",
    "    epochs = mne.Epochs(\n",
    "        raw,\n",
    "        mne_events, \n",
    "        event_id={'WORD':mne_event_id['WORD']}, \n",
    "        event_repeated='drop', \n",
    "        tmin=(settings['rel_start']-settings['buffer_time'])/1000.,\n",
    "        tmax=(settings['rel_stop']+settings['buffer_time'])/1000., \n",
    "        baseline=None, \n",
    "        preload=True\n",
    "    )\n",
    "    epochs.metadata = event_df.query(\"trial_type=='WORD'\").reset_index(drop=True)\n",
    "    all_sessions.append(mne_to_ptsa(epochs))\n",
    "    del epochs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /protocols/ltp/subjects/LTP453/experiments/NiclsCourierReadOnly/sessions/0/ephys/current_processed/LTP453_session_0.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 10989567  =      0.000 ...  5366.000 secs...\n",
      "Not setting metadata\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 120 events and 4097 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "data = cml.get_data_index(kind = 'ltp')\n",
    "data = data[(data['experiment']==settings['experiment'])&(data['subject']==subject)].sort_values('session').reset_index()\n",
    "# cml.CMLReader(subject=subject, experiment=row['experiment'], session=row['session'])\n",
    "r = cml.CMLReader(subject, experiment=settings['experiment'], session=0)\n",
    "evs = r.load('task_events')\n",
    "word_evs = evs[(evs.type=='WORD')&(evs.eegoffset!=-1)]\n",
    "if len(word_evs)==0:\n",
    "    # continue # sync pulses not recorded\n",
    "    print(\"bad!\")\n",
    "eeg = r.load_eeg(word_evs,\n",
    "                    rel_start=settings['rel_start'] - settings['buffer_time'],\n",
    "                    rel_stop=settings['rel_stop'] + settings['buffer_time'],\n",
    "                    clean=settings['clean']\n",
    "                ).to_ptsa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_104457/2155577586.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0meeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mall_sessions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'all'"
     ]
    }
   ],
   "source": [
    "assert (eeg.item == all_sessions[0].item).all()\n",
    "assert (all_sessions[0]['item'].values == eeg['item'].values).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
